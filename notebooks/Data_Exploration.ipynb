{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain Tumor MRI Dataset - Data Exploration & Validation\n",
    "\n",
    "**Objective**: Comprehensive analysis to determine dataset readiness for preprocessing and model training.\n",
    "\n",
    "**Dataset**: 253 MRI brain scans (binary classification: tumor vs no tumor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Structure Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Structure:\n",
      "├── Tumor images: 155\n",
      "├── No tumor images: 98\n",
      "└── Total images: 253\n",
      "\n",
      "Class Distribution:\n",
      "├── Tumor: 61.3%\n",
      "└── No tumor: 38.7%\n",
      "\n",
      "Imbalance Ratio: 0.63 (>0.8 is balanced, >0.6 is acceptable)\n"
     ]
    }
   ],
   "source": [
    "# Define data paths\n",
    "DATA_DIR = Path('./Data')\n",
    "TUMOR_DIR = DATA_DIR / 'yes'\n",
    "NO_TUMOR_DIR = DATA_DIR / 'no'\n",
    "\n",
    "# Collect all image files\n",
    "def get_image_files(directory):\n",
    "    \"\"\"Get all image files from directory with common extensions\"\"\"\n",
    "    extensions = ['.jpg', '.jpeg', '.JPG', '.JPEG', '.png', '.PNG']\n",
    "    files = []\n",
    "    for ext in extensions:\n",
    "        files.extend(directory.glob(f'*{ext}'))\n",
    "    return sorted(files)\n",
    "\n",
    "tumor_files = get_image_files(TUMOR_DIR)\n",
    "no_tumor_files = get_image_files(NO_TUMOR_DIR)\n",
    "\n",
    "print(f\"Dataset Structure:\")\n",
    "print(f\"├── Tumor images: {len(tumor_files)}\")\n",
    "print(f\"├── No tumor images: {len(no_tumor_files)}\")\n",
    "print(f\"└── Total images: {len(tumor_files) + len(no_tumor_files)}\")\n",
    "\n",
    "# Class balance analysis\n",
    "total_images = len(tumor_files) + len(no_tumor_files)\n",
    "tumor_ratio = len(tumor_files) / total_images\n",
    "no_tumor_ratio = len(no_tumor_files) / total_images\n",
    "\n",
    "print(f\"\\nClass Distribution:\")\n",
    "print(f\"├── Tumor: {tumor_ratio:.1%}\")\n",
    "print(f\"└── No tumor: {no_tumor_ratio:.1%}\")\n",
    "\n",
    "# Check for class imbalance\n",
    "imbalance_ratio = min(tumor_ratio, no_tumor_ratio) / max(tumor_ratio, no_tumor_ratio)\n",
    "print(f\"\\nImbalance Ratio: {imbalance_ratio:.2f} (>0.8 is balanced, >0.6 is acceptable)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Image Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_properties(image_files, label):\n",
    "    \"\"\"Analyze basic image properties for quality assessment\"\"\"\n",
    "    properties = {\n",
    "        'widths': [], 'heights': [], 'channels': [],\n",
    "        'file_sizes': [], 'mean_intensity': [],\n",
    "        'std_intensity': [], 'contrast': []\n",
    "    }\n",
    "    \n",
    "    corrupted_files = []\n",
    "    total_files = len(image_files)\n",
    "    \n",
    "    print(f\"Processing {total_files} {label} images...\")\n",
    "    \n",
    "    for i, file_path in enumerate(image_files):\n",
    "        # Progress indicator every 10 images or for last image\n",
    "        if (i + 1) % 10 == 0 or (i + 1) == total_files:\n",
    "            progress = ((i + 1) / total_files) * 100\n",
    "            print(f\"  Progress: {i+1}/{total_files} ({progress:.1f}%)\")\n",
    "            \n",
    "        try:\n",
    "            # Basic file properties\n",
    "            file_size = file_path.stat().st_size / 1024  # KB\n",
    "            \n",
    "            # Load image with validation\n",
    "            img = cv2.imread(str(file_path))\n",
    "            if img is None:\n",
    "                corrupted_files.append(str(file_path))\n",
    "                print(f\"     Failed to load: {file_path.name}\")\n",
    "                continue\n",
    "                \n",
    "            # Validate image dimensions\n",
    "            if len(img.shape) < 2:\n",
    "                corrupted_files.append(str(file_path))\n",
    "                print(f\"     Invalid dimensions: {file_path.name}\")\n",
    "                continue\n",
    "                \n",
    "            # Convert to grayscale for analysis\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Store properties\n",
    "            properties['widths'].append(img.shape[1])\n",
    "            properties['heights'].append(img.shape[0])\n",
    "            properties['channels'].append(img.shape[2] if len(img.shape) > 2 else 1)\n",
    "            properties['file_sizes'].append(file_size)\n",
    "            properties['mean_intensity'].append(np.mean(gray))\n",
    "            properties['std_intensity'].append(np.std(gray))\n",
    "            \n",
    "            # Contrast using Michelson contrast\n",
    "            contrast = (np.max(gray) - np.min(gray)) / (np.max(gray) + np.min(gray) + 1e-8)\n",
    "            properties['contrast'].append(contrast)\n",
    "            \n",
    "        except Exception as e:\n",
    "            corrupted_files.append(str(file_path))\n",
    "            print(f\"     Error processing {file_path.name}: {str(e)}\")\n",
    "    \n",
    "    # Summary\n",
    "    valid_images = total_files - len(corrupted_files)\n",
    "    print(f\"  Successfully analyzed: {valid_images}/{total_files} images\")\n",
    "    if corrupted_files:\n",
    "        print(f\"  Corrupted/Invalid: {len(corrupted_files)} files\")\n",
    "    \n",
    "    return properties, corrupted_files\n",
    "\n",
    "# Analyze both classes with enhanced reporting\n",
    "print(\"=\" * 60)\n",
    "print(\"STARTING IMAGE QUALITY ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nPHASE 1: TUMOR CLASS ANALYSIS\")\n",
    "tumor_props, tumor_corrupted = analyze_image_properties(tumor_files, 'tumor')\n",
    "\n",
    "print(\"\\nPHASE 2: NO TUMOR CLASS ANALYSIS\") \n",
    "no_tumor_props, no_tumor_corrupted = analyze_image_properties(no_tumor_files, 'no_tumor')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total images processed: {len(tumor_files) + len(no_tumor_files)}\")\n",
    "print(f\"Tumor images: {len(tumor_files)} ({len(tumor_files) - len(tumor_corrupted)} valid)\")\n",
    "print(f\"No tumor images: {len(no_tumor_files)} ({len(no_tumor_files) - len(no_tumor_corrupted)} valid)\")\n",
    "\n",
    "print(f\"\\nFile integrity check:\")\n",
    "print(f\"Tumor corrupted: {len(tumor_corrupted)}\")\n",
    "print(f\"No tumor corrupted: {len(no_tumor_corrupted)}\")\n",
    "\n",
    "if tumor_corrupted or no_tumor_corrupted:\n",
    "    print(f\"\\nCORRUPTED FILES DETECTED:\")\n",
    "    for file_path in tumor_corrupted + no_tumor_corrupted:\n",
    "        print(f\"   - {file_path}\")\n",
    "else:\n",
    "    print(f\"\\nALL FILES SUCCESSFULLY VALIDATED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive statistics summary\n",
    "def create_stats_summary(props, label):\n",
    "    \"\"\"Create statistical summary for image properties\"\"\"\n",
    "    stats_data = {}\n",
    "    \n",
    "    for key, values in props.items():\n",
    "        if values:  # Check if list is not empty\n",
    "            stats_data[key] = {\n",
    "                'mean': np.mean(values),\n",
    "                'std': np.std(values),\n",
    "                'min': np.min(values),\n",
    "                'max': np.max(values),\n",
    "                'median': np.median(values)\n",
    "            }\n",
    "    \n",
    "    return pd.DataFrame(stats_data).round(2)\n",
    "\n",
    "tumor_stats = create_stats_summary(tumor_props, 'Tumor')\n",
    "no_tumor_stats = create_stats_summary(no_tumor_props, 'No Tumor')\n",
    "\n",
    "print(\"TUMOR CLASS STATISTICS:\")\n",
    "print(tumor_stats)\n",
    "print(\"\\nNO TUMOR CLASS STATISTICS:\")\n",
    "print(no_tumor_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Resolution and Format Consistency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze resolution consistency\n",
    "all_widths = tumor_props['widths'] + no_tumor_props['widths']\n",
    "all_heights = tumor_props['heights'] + no_tumor_props['heights']\n",
    "\n",
    "width_counts = Counter(all_widths)\n",
    "height_counts = Counter(all_heights)\n",
    "\n",
    "print(\"RESOLUTION ANALYSIS:\")\n",
    "print(f\"Unique widths: {len(width_counts)}\")\n",
    "print(f\"Unique heights: {len(height_counts)}\")\n",
    "print(f\"Most common resolution: {width_counts.most_common(1)[0][0]}x{height_counts.most_common(1)[0][0]}\")\n",
    "print(f\"Resolution consistency: {width_counts.most_common(1)[0][1] / len(all_widths):.1%}\")\n",
    "\n",
    "# Visualize resolution distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Width distribution\n",
    "axes[0].hist([tumor_props['widths'], no_tumor_props['widths']], \n",
    "             bins=20, alpha=0.7, label=['Tumor', 'No Tumor'])\n",
    "axes[0].set_xlabel('Image Width (pixels)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Image Width Distribution')\n",
    "axes[0].legend()\n",
    "\n",
    "# Height distribution\n",
    "axes[1].hist([tumor_props['heights'], no_tumor_props['heights']], \n",
    "             bins=20, alpha=0.7, label=['Tumor', 'No Tumor'])\n",
    "axes[1].set_xlabel('Image Height (pixels)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Image Height Distribution')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Intensity Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze intensity distributions for preprocessing readiness\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Mean intensity comparison\n",
    "axes[0,0].hist([tumor_props['mean_intensity'], no_tumor_props['mean_intensity']], \n",
    "               bins=30, alpha=0.7, label=['Tumor', 'No Tumor'])\n",
    "axes[0,0].set_xlabel('Mean Intensity')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "axes[0,0].set_title('Mean Intensity Distribution')\n",
    "axes[0,0].legend()\n",
    "\n",
    "# Standard deviation comparison\n",
    "axes[0,1].hist([tumor_props['std_intensity'], no_tumor_props['std_intensity']], \n",
    "               bins=30, alpha=0.7, label=['Tumor', 'No Tumor'])\n",
    "axes[0,1].set_xlabel('Intensity Standard Deviation')\n",
    "axes[0,1].set_ylabel('Frequency')\n",
    "axes[0,1].set_title('Intensity Variance Distribution')\n",
    "axes[0,1].legend()\n",
    "\n",
    "# Contrast comparison\n",
    "axes[1,0].hist([tumor_props['contrast'], no_tumor_props['contrast']], \n",
    "               bins=30, alpha=0.7, label=['Tumor', 'No Tumor'])\n",
    "axes[1,0].set_xlabel('Contrast (Michelson)')\n",
    "axes[1,0].set_ylabel('Frequency')\n",
    "axes[1,0].set_title('Image Contrast Distribution')\n",
    "axes[1,0].legend()\n",
    "\n",
    "# File size comparison\n",
    "axes[1,1].hist([tumor_props['file_sizes'], no_tumor_props['file_sizes']], \n",
    "               bins=30, alpha=0.7, label=['Tumor', 'No Tumor'])\n",
    "axes[1,1].set_xlabel('File Size (KB)')\n",
    "axes[1,1].set_ylabel('Frequency')\n",
    "axes[1,1].set_title('File Size Distribution')\n",
    "axes[1,1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical tests for distribution differences\n",
    "print(\"STATISTICAL TESTS FOR CLASS DIFFERENCES:\")\n",
    "intensity_pvalue = stats.mannwhitneyu(tumor_props['mean_intensity'], \n",
    "                                     no_tumor_props['mean_intensity'])[1]\n",
    "contrast_pvalue = stats.mannwhitneyu(tumor_props['contrast'], \n",
    "                                   no_tumor_props['contrast'])[1]\n",
    "\n",
    "print(f\"Mean intensity difference p-value: {intensity_pvalue:.6f}\")\n",
    "print(f\"Contrast difference p-value: {contrast_pvalue:.6f}\")\n",
    "print(f\"Significant difference (p<0.05): {(intensity_pvalue < 0.05) or (contrast_pvalue < 0.05)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sample Images Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample images from both classes\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "\n",
    "# Sample tumor images\n",
    "for i in range(5):\n",
    "    if i < len(tumor_files):\n",
    "        img = cv2.imread(str(tumor_files[i]))\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        axes[0,i].imshow(img_rgb, cmap='gray')\n",
    "        axes[0,i].set_title(f'Tumor {i+1}')\n",
    "        axes[0,i].axis('off')\n",
    "\n",
    "# Sample no tumor images\n",
    "for i in range(5):\n",
    "    if i < len(no_tumor_files):\n",
    "        img = cv2.imread(str(no_tumor_files[i]))\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        axes[1,i].imshow(img_rgb, cmap='gray')\n",
    "        axes[1,i].set_title(f'No Tumor {i+1}')\n",
    "        axes[1,i].axis('off')\n",
    "\n",
    "plt.suptitle('Sample Images from Dataset', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Preprocessing Readiness Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_preprocessing_readiness():\n",
    "    \"\"\"Comprehensive assessment for preprocessing readiness\"\"\"\n",
    "    \n",
    "    readiness_score = 0\n",
    "    max_score = 10\n",
    "    issues = []\n",
    "    recommendations = []\n",
    "    \n",
    "    print(\"PREPROCESSING READINESS ASSESSMENT:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. Class balance (2 points)\n",
    "    if imbalance_ratio > 0.6:\n",
    "        readiness_score += 2\n",
    "        print(\"✓ Class balance: ACCEPTABLE\")\n",
    "    else:\n",
    "        issues.append(\"Severe class imbalance detected\")\n",
    "        recommendations.append(\"Apply class balancing techniques (SMOTE, class weights)\")\n",
    "        print(\"✗ Class balance: POOR\")\n",
    "    \n",
    "    # 2. Corrupted files (1 point)\n",
    "    total_corrupted = len(tumor_corrupted) + len(no_tumor_corrupted)\n",
    "    if total_corrupted == 0:\n",
    "        readiness_score += 1\n",
    "        print(\"✓ File integrity: EXCELLENT\")\n",
    "    else:\n",
    "        issues.append(f\"{total_corrupted} corrupted files found\")\n",
    "        recommendations.append(\"Remove or repair corrupted image files\")\n",
    "        print(f\"⚠ File integrity: {total_corrupted} corrupted files\")\n",
    "    \n",
    "    # 3. Resolution consistency (2 points)\n",
    "    resolution_consistency = width_counts.most_common(1)[0][1] / len(all_widths)\n",
    "    if resolution_consistency > 0.8:\n",
    "        readiness_score += 2\n",
    "        print(\"✓ Resolution consistency: GOOD\")\n",
    "    elif resolution_consistency > 0.5:\n",
    "        readiness_score += 1\n",
    "        print(\"⚠ Resolution consistency: MODERATE\")\n",
    "        recommendations.append(\"Consider standardizing image resolution\")\n",
    "    else:\n",
    "        issues.append(\"High resolution variance\")\n",
    "        recommendations.append(\"Mandatory resolution normalization required\")\n",
    "        print(\"✗ Resolution consistency: POOR\")\n",
    "    \n",
    "    # 4. Dataset size (1 point)\n",
    "    if total_images >= 200:\n",
    "        readiness_score += 1\n",
    "        print(\"✓ Dataset size: ADEQUATE\")\n",
    "    else:\n",
    "        issues.append(\"Small dataset size\")\n",
    "        recommendations.append(\"Consider data augmentation strategies\")\n",
    "        print(\"⚠ Dataset size: SMALL\")\n",
    "    \n",
    "    # 5. Intensity distribution (2 points)\n",
    "    tumor_mean_std = np.std(tumor_props['mean_intensity'])\n",
    "    no_tumor_mean_std = np.std(no_tumor_props['mean_intensity'])\n",
    "    \n",
    "    if tumor_mean_std < 50 and no_tumor_mean_std < 50:\n",
    "        readiness_score += 2\n",
    "        print(\"✓ Intensity consistency: GOOD\")\n",
    "    elif tumor_mean_std < 80 and no_tumor_mean_std < 80:\n",
    "        readiness_score += 1\n",
    "        print(\"⚠ Intensity consistency: MODERATE\")\n",
    "        recommendations.append(\"Apply intensity normalization\")\n",
    "    else:\n",
    "        issues.append(\"High intensity variance\")\n",
    "        recommendations.append(\"Mandatory intensity normalization required\")\n",
    "        print(\"✗ Intensity consistency: POOR\")\n",
    "    \n",
    "    # 6. Image quality (2 points)\n",
    "    avg_contrast = np.mean(tumor_props['contrast'] + no_tumor_props['contrast'])\n",
    "    if avg_contrast > 0.3:\n",
    "        readiness_score += 2\n",
    "        print(\"✓ Image quality: GOOD\")\n",
    "    elif avg_contrast > 0.15:\n",
    "        readiness_score += 1\n",
    "        print(\"⚠ Image quality: MODERATE\")\n",
    "        recommendations.append(\"Consider histogram equalization\")\n",
    "    else:\n",
    "        issues.append(\"Low image contrast\")\n",
    "        recommendations.append(\"Apply contrast enhancement techniques\")\n",
    "        print(\"✗ Image quality: POOR\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(f\"FINAL READINESS SCORE: {readiness_score}/{max_score}\")\n",
    "    \n",
    "    if readiness_score >= 8:\n",
    "        status = \"READY FOR PREPROCESSING\"\n",
    "    elif readiness_score >= 6:\n",
    "        status = \"READY WITH MINOR ADJUSTMENTS\"\n",
    "    elif readiness_score >= 4:\n",
    "        status = \"REQUIRES SIGNIFICANT PREPROCESSING\"\n",
    "    else:\n",
    "        status = \"NOT READY - MAJOR ISSUES DETECTED\"\n",
    "    \n",
    "    print(f\"STATUS: {status}\")\n",
    "    \n",
    "    if issues:\n",
    "        print(\"\\nISSUES IDENTIFIED:\")\n",
    "        for i, issue in enumerate(issues, 1):\n",
    "            print(f\"{i}. {issue}\")\n",
    "    \n",
    "    if recommendations:\n",
    "        print(\"\\nRECOMMENDATIONS:\")\n",
    "        for i, rec in enumerate(recommendations, 1):\n",
    "            print(f\"{i}. {rec}\")\n",
    "    \n",
    "    return readiness_score, status, issues, recommendations\n",
    "\n",
    "readiness_score, status, issues, recommendations = assess_preprocessing_readiness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final Report Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive report\n",
    "report = {\n",
    "    \"dataset_summary\": {\n",
    "        \"total_images\": total_images,\n",
    "        \"tumor_images\": len(tumor_files),\n",
    "        \"no_tumor_images\": len(no_tumor_files),\n",
    "        \"class_imbalance_ratio\": imbalance_ratio,\n",
    "        \"corrupted_files\": len(tumor_corrupted) + len(no_tumor_corrupted)\n",
    "    },\n",
    "    \"technical_specs\": {\n",
    "        \"resolution_consistency\": width_counts.most_common(1)[0][1] / len(all_widths),\n",
    "        \"most_common_resolution\": f\"{width_counts.most_common(1)[0][0]}x{height_counts.most_common(1)[0][0]}\",\n",
    "        \"avg_file_size_kb\": np.mean(tumor_props['file_sizes'] + no_tumor_props['file_sizes']),\n",
    "        \"avg_contrast\": np.mean(tumor_props['contrast'] + no_tumor_props['contrast'])\n",
    "    },\n",
    "    \"readiness_assessment\": {\n",
    "        \"score\": f\"{readiness_score}/10\",\n",
    "        \"status\": status,\n",
    "        \"issues\": issues,\n",
    "        \"recommendations\": recommendations\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save report as JSON\n",
    "with open('data_exploration_report.json', 'w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "print(\"FINAL DATA EXPLORATION REPORT\")\n",
    "print(\"=\" * 50)\n",
    "print(json.dumps(report, indent=2))\n",
    "print(\"\\nReport saved as: data_exploration_report.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This comprehensive data exploration provides essential metrics to determine preprocessing requirements. The dataset shows the following characteristics:\n",
    "\n",
    "- **Dataset Size**: 253 images (adequate for deep learning with augmentation)\n",
    "- **Class Balance**: Slightly imbalanced but manageable\n",
    "- **Image Quality**: MRI scans with varying contrast and resolution\n",
    "- **Preprocessing Needs**: Based on readiness score, specific preprocessing steps are recommended\n",
    "\n",
    "**Next Steps**: Proceed to preprocessing phase based on the recommendations above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
